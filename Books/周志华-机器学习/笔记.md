# 第二章 模型评估与选择
## 2.1 经验误差与过拟合

引起过拟合的可能因素：

- 学习能力过强
  - 决策树扩展分支
  - 神经网络增加训练轮数

## 2.2 模型评估

测试集与训练集互斥
  
有几种方法划分：

- 留出法——尽可能保证分布一致性
- 交叉验证法——十折交叉验证

``` python
sklearn.model_selection.Kflod(n_splits = 3, shuffle = False, random_state = None)
```

n_splits——k折的值
shuffle——对数据是否随机搅动
random_state——随机种子

训练集训练，测试集测试，验证准确度去了是一个<font color = #ff0000> 测试准确度</font>的测量,而测试准确度是一个<font color = #ff0000>高方差估计方法</font>。

- 自助法（bootstrapping）
  
  有放回抽样，抽样到和原始样本同样等级
  适用于<font color = #aaaa>数据集较小</font>的时候

调参与最终模型——计算与性能折中

## 2.3 性能度量

模型好坏：任务需求，算法，数据！
学习器f的预测结果f(x)与y比较

- 回归任务常用“均方误差”：

### 2.3.1 错误率与精度

- 错误率——分类错误的样本数占样本总数的比例
- 精度——分类正确的样本数占总数的比例
- 查准率（precision）：
  
  $\frac{TP}{TP+FP}$
- 查全率（recall）:
  $\frac{TP}{TP+FN}$

两者是一对儿矛盾度量

> 举例:
> >商品推荐系统：更关注查准率

> >罪犯检索系统：更关注查全率

 一般情况下根据学习器的预测结果对样例排序，可绘制出P-R图
如下所示：

<img src="https://github.com/Optimus-Prime-X/Markdown-Photos/blob/master/P-R%E5%9B%BE.png?raw=true" width="500" height="500" align=center />

通过对平衡点的比较可以比较模型的优劣，但是不全面，更多使用$F_1$值进行比较：

$F_1 = \frac{2\cdot P \cdot R}{P+R}$ P,R为precision和recall

$F_1$还可以转变为诶有偏好的$F_\beta$

$$BEP = Precision = Recall$$(2.1)

当准确率等于召回率时，定义BEP

### 2.3.3 ROC与AUC

ROC曲线的坐标：

- 横坐标：假正率 $\frac{FP}{FP+TN}$
- 纵坐标：真正率 $\frac{TP}{TP+FN}$

![ROC & AUC](https://github.com/Optimus-Prime-X/Markdown-Photos/blob/master/ROC_AUC.png?raw=true)

### 2.3.4 代价敏感错误率与代价曲线

为了解决*非均等代价*

对不同的分类可以引入代价：

|真实类别|预测|类别|
|---|:----:|:---:|
||第0类|第1类|
|第0类|0|cost2|
|第1类|cost1|0|

代价曲线：

![代价曲线](https://github.com/Optimus-Prime-X/Markdown-Photos/blob/master/%E4%BB%A3%E4%BB%B7%E6%9B%B2%E7%BA%BF.png?raw=true)

TPN: 真正例率 $TPR = \frac{TP}{TP+FN}$ 等价于召回率
FPR: 假正例率 $FPR = \frac{FP}{TN+FP}$ 

> 记忆方法：TP乘积为正，分母为真实的正例总体，分子为TP；FP，乘积为负，分母为全体的反例，分子为FP

真正例率为正确预测为正例的数量与全体正例的比例，假正例率为错误预测为正例的数量占全体反例的比例。一个好的分类器，应该是TPR高，FPR接近0

代价曲线下方的面积为所有条件下学习器的期望总体代价

## 2.4 比较检验

需要考虑的是，学习器A比B在测试集上表现更优，是否是统计意义上的更优，该把握的大小需要通过假设检验

### 2.4.1 假设检验

首先需要考虑，测试集的观测误差率$\hat{e}$与实际的泛化误差率$e$是否为正确估计，可以证明前者是后者的无偏估计。当比较两个分类器的误差率差别时，可以考虑对两个分类器的一系列观测误差率进行做差，得到一系列的$\Delta e$，对这些$\Delta e$进行t-检验。

### 2.4.2 t-检验
  
$$\mu = \frac{1}{k} \sum_{k=1}^{k} (\hat{e_i})$$(2.2)
$$\sigma^2 = \frac{1}{k-1}\sum_{k=1}^{k}(\hat{e_i}-\mu)^2$$(2.3) 

这k个测试错误率看成是对泛化错误率的独立采样，则变量：

$$\tau_t=\frac{\sqrt{k}(\mu-e_0)}{\sigma}$$

服从自由度为k-1的t分布。因此可以对$\Delta e$进行t检验，判断是否拒绝两个分类器泛化误差率相等的假设。

- 交叉验证t-检验

很多情况下，两个学习器进行交叉验证时，样本存在重复采集，使得测试错误率结果并非完全不相关，一般针对这种情况采用5次2折交叉检验，并对单次交叉检验的$\mu$和$\sigma$进行相应的选择。选择如下：
> 单次两折交叉中，使用两个分类器的测试误差平均值

$$\mu = \frac{\Delta_1^1+\Delta_1^2}{2}$$(2.4)
而方差公式

$$\sigma_i^2 = (\Delta_i^1-\frac{\Delta_i^1+\Delta_i^2}{2})^2+(\Delta_i^2-\frac{\Delta_i^1+\Delta_i^2}{2})^2$$(2.5)

### 2.4.3 McNemar检验

二分类问题，两个分类器还可以形成一个“列联表”，表示学习器共同预测为正，共同预测为负等信息，类似混淆矩阵。
||A-正确|A-错误|
|---|---|---|
|B-正确|$e_{00}$|$e_{10}$|
|B-错误|$e_{01}$|$e_{11}$|

如果两个分类器的学习性能相同，那么$|e_{01}-e_{10}|$应该服从正态分布，因此可以进行$\chi$检验：

$$\chi = \frac{(|e_{01}-e_{10}|)^2-1}{e_{01}+e_{10}}$$(2.6)

### 2.4.4 多个数据集上对多个分类器进行比较

- 基于排序的Friedman检验


### 2.4.5 偏差与方差

$$E(f;D)= bias^2(x) + var(x)+\epsilon^2$$(2.7)

- 偏差：刻画了学习算法的拟合能力
- 方差：度量了训练集的变动引起的学习性能的变化（数据扰动引起的影响）
- 噪声：任何学习算法所能达到的泛化误差下限，刻画了问题本身的难度

一般来说，存在方差和偏差窘境

----

# 第3章 线性模型

## 3.1 简介

写成向量形式：

$$f(x) = \omega^Tx+b$$(3.1)

需要学习的变量为$\omega$和$b$，确定模型。

- 线性模型拥有很棒的可解释性

## 3.2 线性回归

### 3.2.1 单变量线性回归

属性的选择：

- 若属性存在有序，如身高“高”、“矮”，则可以定义有序编码
- 若属性无序，如“黄色”、“红色”，则one-hot编码，该变量存在k个属性则演变成k维编码

通过均方误差定义损失函数，最优化$\omega$和$b$：

$$(\omega^*, b^*) = arg min \sum^m_{i=1}(f(x_i)-y_i)^2$$(3.2)

此为最小二乘法。

### 3.2.2 多元线性回归

$$\omega = (X^TX)^{-1}X^Ty$$
当矩阵$(X^TX)$存在逆时上式成立，常规往往不为满秩矩阵，因此常用方法是<font color=#00FFFF>引入正则化</font>

还可以通过对y进行变形如$lny$

## 3.3 对数几率回归(逻辑回归)

如何使用线性模型进行分类任务？ ——找到一个单调可微函数将<font color = #ffff00>分类任务的标记与线性回归模型的预测值</font>联系起来

naive的想法，定义一个阶跃函数$f(z)$满足当预测值$z=\omega^Tx+b$大于0、等于0、小于0时分别为0, 0.5和1

但是这个阶跃函数不连续，因此为找到一个近似的单位阶跃函数，我们选择对数几率函数即sigmoid函数:

$$y = \frac{1}{1+e^{-z}}=\frac{1}{1+e^{-(\omega^Tx+b)}}$$(3.3)
变化后可得：

$$\ln(\frac{y}{1-y})=\omega^Tx+b$$(3.4)
把y想象成样本x作为正例的可能性，则1-y为其成为反例的可能性，两者比值定义为<font color=#00ffff>对数几率</font>

这类方法的优点是：
- 直接对分类可能性进行建模，无需事先假设数据分布
- 得到的是近似概率的预测
- 有良好的数学性质

如何学得$\omega$与b呢，重写式(3.4)得如下：

$$\ln(\frac{p(y=1|x)}{p(y=0|x)}) = \omega^Tx+b$$(3.5)

采用极大似然估计$\omega$与b

$$l(\omega,b) = \sum^m_{i=1}\ln p(y_i|x_i;\omega,b)$$(3.6)

## 3.4 线性判别分析(LDA)

和逻辑回归之间的需要区分

LDA的思想： 设法将给定训练集样例投影到一条直线上，使得同类样例能尽可能靠近，异类样例能尽可能远离

基于这个思想，需要进行两步操作，假设$X_i,\mu_i,\Sigma_i$分别为类的样例集合，样例均值，样例协方差矩阵
- 同类样例尽可能靠近，则协方差尽可能小，构造$\omega^T\Sigma_0\omega + \omega^T\Sigma_1\omega$尽可能小
- 异类样例尽可能远离，则在曲线上的均值尽可能远$||\omega^T\mu_0-\omega^T\mu_1||^2_2$尽可能大。

最优化目标——“类内散度矩阵”：

$$J = \frac{||\omega^T\mu_0-\omega^T\mu_1||^2_2}{\omega^T\Sigma_0\omega + \omega^T\Sigma_1\omega}$$(3.7)

最优化问题采用拉格朗日乘子法，约束为(3.7)式分母为1。如此构造无约束的函数形式，手写一下熟悉熟悉！

## 3.5 多分类学习

多分类问题常用拆解法的思路
- OvO：挑选训练集中$C_i$与$C_j$类进行训练，最终得到$\frac{n(n-1)}{2}$个分类器，对测试集应用这些分类器，对最终结果进行投票。
- OvM：每次进行1 v N-1进行划分，最终训练出N个分类器

如果考虑分类器的存储开销，OvM模式更有利，但是当数据量较大且类别较多时，OvM模式每次训练均需要训练多个模型，反而时间开销大，实际问题需要取舍。两者的性能在多数情况下接近。


- MvM：不能随意分类，最常用的模式——“纠错输出码”ECOC
  - 编码：对N个类别做M次划分，每次划分为一部分类为正，一部分为负，这样产生M个训练器，可以对一个类别的数据进行编码
  - 解码，预测码与每个类别实际的编码进行比较，返回距离最小的类别编号作为最终的预测结果

类别划分通过“编码矩阵”，常见的为二元码和三元码，形成编码矩阵：

1. 为什么成为“纠错输出码”？：

    - 编码越长，单个分类器的错误引起的最终分类错误可能性更低。

Tips： 但是编码过长会引起训练开销增大

2. 如何选择编码方式？
    - 不需要过多考虑，首先是个NP难问题，其次机器学习涉及的问题过于复杂，往往非最优编码已经能达到效果了

## 3.6 类别不平衡问题

考虑线性分类器$y = \omega^Tx+b$对新样本x进行分类时，通常y为一个概率值，当不平衡样例集的正例和反例分别为$m^+$和$m^-$时，应当满足正例判别条件：

$$\frac{y}{1-y} > \frac{m^+}{m^-}$$

但上述想法往往行不通，原因是基于假设：“训练集是真实样本总体的无偏采样”这一观点并不成立。

基于上述问题，可以采用如下几种方法解决类别不平衡问题：
- 欠采样：代表性方法EasyEnsemble
- 过采样：代表性方法SMOTE
- 阈值移动（刚才的方法WTF？）